{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84e9b6b",
   "metadata": {},
   "source": [
    "###  Shyam bhaskar (Roll Number:S20210010035)\n",
    "### Yalakanti Eswar (Roll Number:S20210020332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b27efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hvplot.pandas\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.svm import SVR\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense,Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d5746b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>43820</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43820</th>\n",
       "      <td>43821</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43821</th>\n",
       "      <td>43822</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43822</th>\n",
       "      <td>43823</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43823</th>\n",
       "      <td>43824</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43824 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd     Iws  \\\n",
       "0          1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW    1.79   \n",
       "1          2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW    4.92   \n",
       "2          3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW    6.71   \n",
       "3          4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW    9.84   \n",
       "4          5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW   12.97   \n",
       "...      ...   ...    ...  ...   ...    ...   ...   ...     ...  ...     ...   \n",
       "43819  43820  2014     12   31    19    8.0   -23  -2.0  1034.0   NW  231.97   \n",
       "43820  43821  2014     12   31    20   10.0   -22  -3.0  1034.0   NW  237.78   \n",
       "43821  43822  2014     12   31    21   10.0   -22  -3.0  1034.0   NW  242.70   \n",
       "43822  43823  2014     12   31    22    8.0   -22  -4.0  1034.0   NW  246.72   \n",
       "43823  43824  2014     12   31    23   12.0   -21  -3.0  1034.0   NW  249.85   \n",
       "\n",
       "       Is  Ir  \n",
       "0       0   0  \n",
       "1       0   0  \n",
       "2       0   0  \n",
       "3       0   0  \n",
       "4       0   0  \n",
       "...    ..  ..  \n",
       "43819   0   0  \n",
       "43820   0   0  \n",
       "43821   0   0  \n",
       "43822   0   0  \n",
       "43823   0   0  \n",
       "\n",
       "[43824 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"PRSA_data_2010.1.1-2014.12.31.csv\")\n",
    "# df.columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978d1420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2aba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fffd93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41757, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eada7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd   Iws  Is  Ir\n",
       "24  2010      1    2     0  129.0   -16  -4.0  1020.0   SE  1.79   0   0\n",
       "25  2010      1    2     1  148.0   -15  -4.0  1020.0   SE  2.68   0   0\n",
       "26  2010      1    2     2  159.0   -11  -5.0  1021.0   SE  3.57   0   0\n",
       "27  2010      1    2     3  181.0    -7  -5.0  1022.0   SE  5.36   1   0\n",
       "28  2010      1    2     4  138.0    -7  -5.0  1022.0   SE  6.25   2   0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "222a4248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hour\n",
       "0     113.390202\n",
       "1     113.698567\n",
       "2     110.323174\n",
       "3     108.042980\n",
       "4     104.080275\n",
       "5     100.013218\n",
       "6      96.882759\n",
       "7      96.024727\n",
       "8      95.907940\n",
       "9      94.672800\n",
       "10     93.447520\n",
       "11     91.678633\n",
       "12     89.448873\n",
       "13     87.990280\n",
       "14     86.283247\n",
       "15     85.534215\n",
       "16     85.922280\n",
       "17     87.571183\n",
       "18     91.507710\n",
       "19     97.398393\n",
       "20    104.614368\n",
       "21    109.249856\n",
       "22    111.021252\n",
       "23    111.889782\n",
       "Name: pm2.5, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data = df.groupby('hour')['pm2.5'].mean()\n",
    "hourly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0110f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('day').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f949b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cbwd'] = df['cbwd'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2909e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cbwd = pd.get_dummies(df['cbwd'], prefix='cbwd')\n",
    "\n",
    "# Concatenate the encoded columns with the original DataFrame\n",
    "df_encoded = pd.concat([df, encoded_cbwd], axis=1)\n",
    "\n",
    "# Drop the original 'cbwd' column as it's no longer needed\n",
    "df_encoded.drop('cbwd', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030df4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.605"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_encoded.drop(columns=['pm2.5'])\n",
    "y = (np.round(np.log(df_encoded['pm2.5'] + 0.01),3)).astype('float')\n",
    "min(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daecc66",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249eeeae",
   "metadata": {},
   "source": [
    "### ANN with SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a651f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4922d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "x_sc_tr=X_train1\n",
    "x_sc_te=X_test1\n",
    "x_sc_tr.iloc[:,:-4] = scaler.fit_transform(X_train1.iloc[:,:-4])\n",
    "x_sc_te.iloc[:,:-4] = scaler.transform(X_test1.iloc[:,:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbcd1e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "824/836 [============================>.] - ETA: 0s - loss: 5.0587\n",
      "Epoch 1: val_loss improved from inf to 0.62186, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 7s 5ms/step - loss: 5.0006 - val_loss: 0.6219\n",
      "Epoch 2/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.6488\n",
      "Epoch 2: val_loss improved from 0.62186 to 0.54708, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.6489 - val_loss: 0.5471\n",
      "Epoch 3/100\n",
      "829/836 [============================>.] - ETA: 0s - loss: 0.6054\n",
      "Epoch 3: val_loss improved from 0.54708 to 0.52543, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.6048 - val_loss: 0.5254\n",
      "Epoch 4/100\n",
      "824/836 [============================>.] - ETA: 0s - loss: 0.5739\n",
      "Epoch 4: val_loss improved from 0.52543 to 0.49554, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.5731 - val_loss: 0.4955\n",
      "Epoch 5/100\n",
      "827/836 [============================>.] - ETA: 0s - loss: 0.5607\n",
      "Epoch 5: val_loss improved from 0.49554 to 0.47207, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.5603 - val_loss: 0.4721\n",
      "Epoch 6/100\n",
      "829/836 [============================>.] - ETA: 0s - loss: 0.5497\n",
      "Epoch 6: val_loss improved from 0.47207 to 0.46235, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.5502 - val_loss: 0.4623\n",
      "Epoch 7/100\n",
      "835/836 [============================>.] - ETA: 0s - loss: 0.5385\n",
      "Epoch 7: val_loss improved from 0.46235 to 0.45954, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.5385 - val_loss: 0.4595\n",
      "Epoch 8/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.5256\n",
      "Epoch 8: val_loss improved from 0.45954 to 0.43671, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.5254 - val_loss: 0.4367\n",
      "Epoch 9/100\n",
      "826/836 [============================>.] - ETA: 0s - loss: 0.5175\n",
      "Epoch 9: val_loss improved from 0.43671 to 0.43490, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.5178 - val_loss: 0.4349\n",
      "Epoch 10/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.5151\n",
      "Epoch 10: val_loss improved from 0.43490 to 0.43148, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.5148 - val_loss: 0.4315\n",
      "Epoch 11/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.5036\n",
      "Epoch 11: val_loss improved from 0.43148 to 0.40956, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.5030 - val_loss: 0.4096\n",
      "Epoch 12/100\n",
      "835/836 [============================>.] - ETA: 0s - loss: 0.4921\n",
      "Epoch 12: val_loss improved from 0.40956 to 0.39906, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4921 - val_loss: 0.3991\n",
      "Epoch 13/100\n",
      "835/836 [============================>.] - ETA: 0s - loss: 0.4852\n",
      "Epoch 13: val_loss improved from 0.39906 to 0.39897, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4852 - val_loss: 0.3990\n",
      "Epoch 14/100\n",
      "835/836 [============================>.] - ETA: 0s - loss: 0.4777\n",
      "Epoch 14: val_loss improved from 0.39897 to 0.39570, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4778 - val_loss: 0.3957\n",
      "Epoch 15/100\n",
      "821/836 [============================>.] - ETA: 0s - loss: 0.4731\n",
      "Epoch 15: val_loss improved from 0.39570 to 0.38781, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4723 - val_loss: 0.3878\n",
      "Epoch 16/100\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.4617\n",
      "Epoch 16: val_loss improved from 0.38781 to 0.38107, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4617 - val_loss: 0.3811\n",
      "Epoch 17/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.4659\n",
      "Epoch 17: val_loss improved from 0.38107 to 0.36773, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4659 - val_loss: 0.3677\n",
      "Epoch 18/100\n",
      "834/836 [============================>.] - ETA: 0s - loss: 0.4534\n",
      "Epoch 18: val_loss did not improve from 0.36773\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4536 - val_loss: 0.3743\n",
      "Epoch 19/100\n",
      "829/836 [============================>.] - ETA: 0s - loss: 0.4571\n",
      "Epoch 19: val_loss did not improve from 0.36773\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4572 - val_loss: 0.3707\n",
      "Epoch 20/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.4523\n",
      "Epoch 20: val_loss improved from 0.36773 to 0.36689, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4527 - val_loss: 0.3669\n",
      "Epoch 21/100\n",
      "831/836 [============================>.] - ETA: 0s - loss: 0.4449\n",
      "Epoch 21: val_loss improved from 0.36689 to 0.36640, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4450 - val_loss: 0.3664\n",
      "Epoch 22/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.4397\n",
      "Epoch 22: val_loss improved from 0.36640 to 0.35408, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4398 - val_loss: 0.3541\n",
      "Epoch 23/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.4385\n",
      "Epoch 23: val_loss did not improve from 0.35408\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4390 - val_loss: 0.3703\n",
      "Epoch 24/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.4349\n",
      "Epoch 24: val_loss improved from 0.35408 to 0.35134, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4350 - val_loss: 0.3513\n",
      "Epoch 25/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.4345\n",
      "Epoch 25: val_loss did not improve from 0.35134\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4346 - val_loss: 0.3729\n",
      "Epoch 26/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.4294\n",
      "Epoch 26: val_loss improved from 0.35134 to 0.33806, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4294 - val_loss: 0.3381\n",
      "Epoch 27/100\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.4321\n",
      "Epoch 27: val_loss did not improve from 0.33806\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4321 - val_loss: 0.3469\n",
      "Epoch 28/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.4283\n",
      "Epoch 28: val_loss did not improve from 0.33806\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4277 - val_loss: 0.3553\n",
      "Epoch 29/100\n",
      "824/836 [============================>.] - ETA: 0s - loss: 0.4270\n",
      "Epoch 29: val_loss did not improve from 0.33806\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4272 - val_loss: 0.3558\n",
      "Epoch 30/100\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.4248\n",
      "Epoch 30: val_loss did not improve from 0.33806\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4248 - val_loss: 0.3389\n",
      "Epoch 31/100\n",
      "835/836 [============================>.] - ETA: 0s - loss: 0.4186\n",
      "Epoch 31: val_loss improved from 0.33806 to 0.33761, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4186 - val_loss: 0.3376\n",
      "Epoch 32/100\n",
      "829/836 [============================>.] - ETA: 0s - loss: 0.4245\n",
      "Epoch 32: val_loss improved from 0.33761 to 0.33584, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4241 - val_loss: 0.3358\n",
      "Epoch 33/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.4211\n",
      "Epoch 33: val_loss did not improve from 0.33584\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4215 - val_loss: 0.3384\n",
      "Epoch 34/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.4228\n",
      "Epoch 34: val_loss improved from 0.33584 to 0.33356, saving model to model_checkpoint.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4227 - val_loss: 0.3336\n",
      "Epoch 35/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.4143\n",
      "Epoch 35: val_loss did not improve from 0.33356\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4153 - val_loss: 0.3386\n",
      "Epoch 36/100\n",
      "829/836 [============================>.] - ETA: 0s - loss: 0.4167\n",
      "Epoch 36: val_loss did not improve from 0.33356\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4170 - val_loss: 0.3451\n",
      "Epoch 37/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.4131\n",
      "Epoch 37: val_loss improved from 0.33356 to 0.33347, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4126 - val_loss: 0.3335\n",
      "Epoch 38/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.4145\n",
      "Epoch 38: val_loss improved from 0.33347 to 0.32952, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4154 - val_loss: 0.3295\n",
      "Epoch 39/100\n",
      "831/836 [============================>.] - ETA: 0s - loss: 0.4129\n",
      "Epoch 39: val_loss did not improve from 0.32952\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4135 - val_loss: 0.3326\n",
      "Epoch 40/100\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.4101\n",
      "Epoch 40: val_loss improved from 0.32952 to 0.32677, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4101 - val_loss: 0.3268\n",
      "Epoch 41/100\n",
      "834/836 [============================>.] - ETA: 0s - loss: 0.4138\n",
      "Epoch 41: val_loss improved from 0.32677 to 0.32029, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4141 - val_loss: 0.3203\n",
      "Epoch 42/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.4089\n",
      "Epoch 42: val_loss did not improve from 0.32029\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4093 - val_loss: 0.3214\n",
      "Epoch 43/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.4104\n",
      "Epoch 43: val_loss did not improve from 0.32029\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4108 - val_loss: 0.3249\n",
      "Epoch 44/100\n",
      "821/836 [============================>.] - ETA: 0s - loss: 0.4079\n",
      "Epoch 44: val_loss did not improve from 0.32029\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4073 - val_loss: 0.3209\n",
      "Epoch 45/100\n",
      "831/836 [============================>.] - ETA: 0s - loss: 0.4058\n",
      "Epoch 45: val_loss did not improve from 0.32029\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4054 - val_loss: 0.3285\n",
      "Epoch 46/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.3986\n",
      "Epoch 46: val_loss did not improve from 0.32029\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3989 - val_loss: 0.3280\n",
      "Epoch 47/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.3973\n",
      "Epoch 47: val_loss did not improve from 0.32029\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3971 - val_loss: 0.3245\n",
      "Epoch 48/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3969\n",
      "Epoch 48: val_loss improved from 0.32029 to 0.31741, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3967 - val_loss: 0.3174\n",
      "Epoch 49/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3964\n",
      "Epoch 49: val_loss did not improve from 0.31741\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3965 - val_loss: 0.3210\n",
      "Epoch 50/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.4017\n",
      "Epoch 50: val_loss did not improve from 0.31741\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4019 - val_loss: 0.3386\n",
      "Epoch 51/100\n",
      "826/836 [============================>.] - ETA: 0s - loss: 0.3964\n",
      "Epoch 51: val_loss improved from 0.31741 to 0.31737, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3968 - val_loss: 0.3174\n",
      "Epoch 52/100\n",
      "825/836 [============================>.] - ETA: 0s - loss: 0.4032\n",
      "Epoch 52: val_loss did not improve from 0.31737\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.4039 - val_loss: 0.3189\n",
      "Epoch 53/100\n",
      "829/836 [============================>.] - ETA: 0s - loss: 0.3954\n",
      "Epoch 53: val_loss improved from 0.31737 to 0.31617, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3947 - val_loss: 0.3162\n",
      "Epoch 54/100\n",
      "827/836 [============================>.] - ETA: 0s - loss: 0.3925\n",
      "Epoch 54: val_loss improved from 0.31617 to 0.31397, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3918 - val_loss: 0.3140\n",
      "Epoch 55/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3913\n",
      "Epoch 55: val_loss did not improve from 0.31397\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3915 - val_loss: 0.3149\n",
      "Epoch 56/100\n",
      "822/836 [============================>.] - ETA: 0s - loss: 0.3901\n",
      "Epoch 56: val_loss improved from 0.31397 to 0.31388, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3893 - val_loss: 0.3139\n",
      "Epoch 57/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3940\n",
      "Epoch 57: val_loss improved from 0.31388 to 0.31121, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3942 - val_loss: 0.3112\n",
      "Epoch 58/100\n",
      "835/836 [============================>.] - ETA: 0s - loss: 0.3880\n",
      "Epoch 58: val_loss improved from 0.31121 to 0.31118, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3880 - val_loss: 0.3112\n",
      "Epoch 59/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.3898\n",
      "Epoch 59: val_loss improved from 0.31118 to 0.30969, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3895 - val_loss: 0.3097\n",
      "Epoch 60/100\n",
      "835/836 [============================>.] - ETA: 0s - loss: 0.3937\n",
      "Epoch 60: val_loss did not improve from 0.30969\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3937 - val_loss: 0.3105\n",
      "Epoch 61/100\n",
      "823/836 [============================>.] - ETA: 0s - loss: 0.3865\n",
      "Epoch 61: val_loss improved from 0.30969 to 0.30953, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3865 - val_loss: 0.3095\n",
      "Epoch 62/100\n",
      "826/836 [============================>.] - ETA: 0s - loss: 0.3860\n",
      "Epoch 62: val_loss improved from 0.30953 to 0.30545, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3861 - val_loss: 0.3054\n",
      "Epoch 63/100\n",
      "827/836 [============================>.] - ETA: 0s - loss: 0.3829\n",
      "Epoch 63: val_loss did not improve from 0.30545\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3828 - val_loss: 0.3057\n",
      "Epoch 64/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3852\n",
      "Epoch 64: val_loss improved from 0.30545 to 0.30020, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3858 - val_loss: 0.3002\n",
      "Epoch 65/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.3842\n",
      "Epoch 65: val_loss improved from 0.30020 to 0.29903, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3842 - val_loss: 0.2990\n",
      "Epoch 66/100\n",
      "831/836 [============================>.] - ETA: 0s - loss: 0.3901\n",
      "Epoch 66: val_loss did not improve from 0.29903\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3899 - val_loss: 0.3013\n",
      "Epoch 67/100\n",
      "835/836 [============================>.] - ETA: 0s - loss: 0.3860\n",
      "Epoch 67: val_loss improved from 0.29903 to 0.29568, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3862 - val_loss: 0.2957\n",
      "Epoch 68/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3822\n",
      "Epoch 68: val_loss did not improve from 0.29568\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3821 - val_loss: 0.2986\n",
      "Epoch 69/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.3864\n",
      "Epoch 69: val_loss did not improve from 0.29568\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3860 - val_loss: 0.2961\n",
      "Epoch 70/100\n",
      "831/836 [============================>.] - ETA: 0s - loss: 0.3798\n",
      "Epoch 70: val_loss improved from 0.29568 to 0.29518, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3796 - val_loss: 0.2952\n",
      "Epoch 71/100\n",
      "831/836 [============================>.] - ETA: 0s - loss: 0.3763\n",
      "Epoch 71: val_loss did not improve from 0.29518\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3763 - val_loss: 0.2981\n",
      "Epoch 72/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.3762\n",
      "Epoch 72: val_loss did not improve from 0.29518\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3762 - val_loss: 0.3035\n",
      "Epoch 73/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3764\n",
      "Epoch 73: val_loss did not improve from 0.29518\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3769 - val_loss: 0.3056\n",
      "Epoch 74/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.3767\n",
      "Epoch 74: val_loss did not improve from 0.29518\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3769 - val_loss: 0.2958\n",
      "Epoch 75/100\n",
      "836/836 [==============================] - ETA: 0s - loss: 0.3741\n",
      "Epoch 75: val_loss improved from 0.29518 to 0.29052, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3741 - val_loss: 0.2905\n",
      "Epoch 76/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.3733\n",
      "Epoch 76: val_loss improved from 0.29052 to 0.28567, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3736 - val_loss: 0.2857\n",
      "Epoch 77/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.3714\n",
      "Epoch 77: val_loss did not improve from 0.28567\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3717 - val_loss: 0.2924\n",
      "Epoch 78/100\n",
      "834/836 [============================>.] - ETA: 0s - loss: 0.3769\n",
      "Epoch 78: val_loss did not improve from 0.28567\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3769 - val_loss: 0.2892\n",
      "Epoch 79/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3721\n",
      "Epoch 79: val_loss did not improve from 0.28567\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3718 - val_loss: 0.2871\n",
      "Epoch 80/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.3694\n",
      "Epoch 80: val_loss did not improve from 0.28567\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3697 - val_loss: 0.2877\n",
      "Epoch 81/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.3715\n",
      "Epoch 81: val_loss did not improve from 0.28567\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3715 - val_loss: 0.2922\n",
      "Epoch 82/100\n",
      "829/836 [============================>.] - ETA: 0s - loss: 0.3713\n",
      "Epoch 82: val_loss did not improve from 0.28567\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3710 - val_loss: 0.3007\n",
      "Epoch 83/100\n",
      "827/836 [============================>.] - ETA: 0s - loss: 0.3707\n",
      "Epoch 83: val_loss did not improve from 0.28567\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3708 - val_loss: 0.2901\n",
      "Epoch 84/100\n",
      "829/836 [============================>.] - ETA: 0s - loss: 0.3732\n",
      "Epoch 84: val_loss improved from 0.28567 to 0.28406, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3733 - val_loss: 0.2841\n",
      "Epoch 85/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.3631\n",
      "Epoch 85: val_loss did not improve from 0.28406\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3631 - val_loss: 0.2844\n",
      "Epoch 86/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3674\n",
      "Epoch 86: val_loss did not improve from 0.28406\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3677 - val_loss: 0.2929\n",
      "Epoch 87/100\n",
      "824/836 [============================>.] - ETA: 0s - loss: 0.3697\n",
      "Epoch 87: val_loss did not improve from 0.28406\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3696 - val_loss: 0.2852\n",
      "Epoch 88/100\n",
      "823/836 [============================>.] - ETA: 0s - loss: 0.3666\n",
      "Epoch 88: val_loss did not improve from 0.28406\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3660 - val_loss: 0.3003\n",
      "Epoch 89/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.3682\n",
      "Epoch 89: val_loss improved from 0.28406 to 0.27890, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3678 - val_loss: 0.2789\n",
      "Epoch 90/100\n",
      "831/836 [============================>.] - ETA: 0s - loss: 0.3663\n",
      "Epoch 90: val_loss did not improve from 0.27890\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3661 - val_loss: 0.2792\n",
      "Epoch 91/100\n",
      "822/836 [============================>.] - ETA: 0s - loss: 0.3691\n",
      "Epoch 91: val_loss improved from 0.27890 to 0.27574, saving model to model_checkpoint.h5\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3687 - val_loss: 0.2757\n",
      "Epoch 92/100\n",
      "833/836 [============================>.] - ETA: 0s - loss: 0.3628\n",
      "Epoch 92: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3626 - val_loss: 0.2813\n",
      "Epoch 93/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.3648\n",
      "Epoch 93: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3648 - val_loss: 0.2839\n",
      "Epoch 94/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3550\n",
      "Epoch 94: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3550 - val_loss: 0.2799\n",
      "Epoch 95/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.3608\n",
      "Epoch 95: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3614 - val_loss: 0.2792\n",
      "Epoch 96/100\n",
      "832/836 [============================>.] - ETA: 0s - loss: 0.3580\n",
      "Epoch 96: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3579 - val_loss: 0.2774\n",
      "Epoch 97/100\n",
      "826/836 [============================>.] - ETA: 0s - loss: 0.3627\n",
      "Epoch 97: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3628 - val_loss: 0.2811\n",
      "Epoch 98/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.3566\n",
      "Epoch 98: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3567 - val_loss: 0.2794\n",
      "Epoch 99/100\n",
      "828/836 [============================>.] - ETA: 0s - loss: 0.3569\n",
      "Epoch 99: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3568 - val_loss: 0.2930\n",
      "Epoch 100/100\n",
      "830/836 [============================>.] - ETA: 0s - loss: 0.3594\n",
      "Epoch 100: val_loss did not improve from 0.27574\n",
      "836/836 [==============================] - 4s 5ms/step - loss: 0.3590 - val_loss: 0.2858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2358ee1f9d0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_model = Sequential([\n",
    "        Dense(256, activation='tanh', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2), \n",
    "    Dense(128, activation='tanh', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),          \n",
    "    Dense(64, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='tanh'),\n",
    "    BatchNormalization(),\n",
    "    Dense(12) \n",
    "])\n",
    "\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "checkpoint_path = \"model_checkpoint.h5\"\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "ann_model.fit(x_sc_tr, y_train1, epochs=100, batch_size=32, validation_split=0.2,callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd5050d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1044/1044 [==============================] - 2s 2ms/step\n",
      "261/261 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "loade_model = load_model(checkpoint_path)\n",
    "extracted_features_train = loade_model.predict(x_sc_tr)\n",
    "extracted_features_test = loade_model.predict(x_sc_te)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_extracted_features_train = scaler.fit_transform(extracted_features_train)\n",
    "scaled_extracted_features_test = scaler.transform(extracted_features_test)\n",
    "\n",
    "\n",
    "svr_model = SVR(C=10, kernel='rbf')\n",
    "svr_model.fit(scaled_extracted_features_train, y_train1)\n",
    "\n",
    "y_pred = svr_model.predict(scaled_extracted_features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "78acd42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4060975920108758\n",
      "0.7259723402106982\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2_scores=r2_score(y_test,y_pred)\n",
    "print('The MSE VALUE:',mean_absolute_error(y_test,y_pred))\n",
    "print(\"The MAE :\",mean_absolute_error(y_test,y_pred))\n",
    "print('the R-squared value:',r2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949ac96",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0957d320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.6142367499177182\n",
      "R^2 Score: 0.42277517048720126\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model Training\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"The MAE :\",mean_absolute_error(y_test,y_pred))\n",
    "print(\"R^2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b9b1ee",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786158a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svr = SVR(C=10, kernel='rbf')\n",
    "model_svr.fit(X_train_scaled, y_train)\n",
    "y_pred_svr = model_svr.predict(X_test_scaled)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "print(\"\\nSupport Vector Regression:\")\n",
    "print(\"Mean Squared Error:\", mse_svr)\n",
    "print(\"The MAE :\",mean_absolute_error(y_test,y_pred))\n",
    "print(\"R^2 Score:\", r2_svr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5bdba",
   "metadata": {},
   "source": [
    "### Polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a9af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3)  # You can adjust the degree as needed\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "model_plr = LinearRegression()\n",
    "model_plr.fit(X_train_poly, y_train)\n",
    "y_pred_plr = model_plr.predict(X_test_poly)\n",
    "mse_plr = mean_squared_error(y_test, y_pred_plr)\n",
    "r2_plr = r2_score(y_test, y_pred_plr)\n",
    "\n",
    "print(\"\\nPolynomial Regression:\")\n",
    "print(\"Mean Squared Error:\", mse_plr)\n",
    "print(\"The MAE :\",mean_absolute_error(y_test,y_pred))\n",
    "print(\"R^2 Score:\", r2_plr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fceb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
